{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning del modelo BETO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autor: Alberto Ramos Sánchez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contenido\n",
    "\n",
    "* [Fine-tuning del modelo BETO](#Fine-tuning-del-modelo-BETO)\n",
    "* [Dataset: TASS](#Dataset:-TASS)\n",
    "* [Preparar tweets](#Preparar-tweets)\n",
    "* [Crear dataset de entrenamiento](#Crear-dataset-de-entrenamiento)\n",
    "    * [Tokenizar contenido](#Tokenizar-contenido)\n",
    "    * [Sets de entrenamiento, validación y test](#Sets-de-entrenamiento,-validación-y-test)\n",
    "    * [Crear dataset](#Crear-dataset)\n",
    "* [Modelo de clasificación *Bert*](#Modelo-de-clasificación-*Bert*)\n",
    "* [Entrenamiento](#Entrenamiento)\n",
    "    * [Evaluación](#Evaluación)\n",
    "* [Resultados](#Resultados)\n",
    "    * [Con 3 clases](#Con-3-clases)\n",
    "        * [Entrenamiento](#Entrenamiento)\n",
    "        * [Validación](#Validación)\n",
    "        * [Test](#Test)\n",
    "    * [Con 6 clases](#Con-6-clases)\n",
    "        * [Entrenamiento](#Entrenamiento)\n",
    "        * [Validation](#Validation)\n",
    "        * [Test](#Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, AdamW\n",
    "\n",
    "from pytorchtools.pytorchtools import EarlyStopping\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "# seed\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este *notebook* se ha entrenado el modelo *Bert* para realizar *sentiment analysis* sobre el conjunto de tweets en español de TASS. El entrenamiento se ha llevado a cabo haciendo *finetuning* sobre la versión para español de *Bert* [*BETO*](https://github.com/dccuchile/beto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: TASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha trabajado con los *datasets* de tweets de [*TASS SEPLN*](http://tass.sepln.org/tass_data/download.php) desde el año 2012 al 2019. \n",
    "Todos los ficheros *xml* se han unido en un único dataset contenido en los ficheros *tweets.csv.gz*, *topics.csv.gz* y *polarities.csv.gz*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"./TASS/conversion_result/dataset31k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv(dataset_path / Path(\"tweets.csv.gz\"), compression='gzip', header=0, sep=';', quotechar='\"')\n",
    "df_topics = pd.read_csv(dataset_path / Path(\"topics.csv.gz\"), compression='gzip', header=0, sep=';', quotechar='\"')\n",
    "df_polarities = pd.read_csv(dataset_path / Path(\"polarities.csv.gz\"), compression='gzip', header=0, sep=';', quotechar='\"')\n",
    "\n",
    "df_topics = df_topics.rename(columns={'tweetid_fk': 'tweetid'})\n",
    "df_polarities = df_polarities.rename(columns={'tweetid_fk': 'tweetid'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En total, en el dataset hay aproximadamente 31 mil tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Número total de tweets = 31375'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Número total de tweets = {len(df_tweets)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y están etiquetados en 6 categorías:\n",
    "\n",
    "* P+ : Positivo fuerte (strong negative)\n",
    "* P : Positivo\n",
    "* NONE : Sin sentimiento (no sentiment tag)\n",
    "* NEU : Neutro\n",
    "* N : Negativo\n",
    "* N+ : Negativo fuerte (strong negative)\n",
    "\n",
    "En la siguiente tabla se muestra la cantidad de tweets por categoría:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Número de tweets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>6219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N+</th>\n",
       "      <td>976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEU</th>\n",
       "      <td>2755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONE</th>\n",
       "      <td>5597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>5442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P+</th>\n",
       "      <td>2793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Número de tweets\n",
       "value                  \n",
       "N                  6219\n",
       "N+                  976\n",
       "NEU                2755\n",
       "NONE               5597\n",
       "P                  5442\n",
       "P+                 2793"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polarities[['value', 'tweetid']].drop_duplicates(subset='tweetid', keep=\"first\").groupby(\"value\").count().rename(columns={\"value\": \"Categoría\", \"tweetid\": \"Número de tweets\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado preprocesamos el texto de los tweets para entrenar el modelo.\n",
    "\n",
    "En la función *clean_tweet* limpiamos el texto quedándonos solamente con los caractéres alfanuméricos. Eliminamos los nombres de usuario, url, vocales seguidas repetidas más de dos veces, tabulaciones, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(text):\n",
    "    res_txt = re.sub(\"@\\w+\", \"\", text) # drop username\n",
    "    res_txt = re.sub(\"https?://[A-Za-z0-9\\./]+\", \"\", res_txt) # drop url\n",
    "    \n",
    "    for p in string.punctuation:\n",
    "        res_txt = res_txt.replace(p, \" \")\n",
    "    #res_txt = \" \".join([c for c in res_txt if c not in string.punctuation])\n",
    "    \n",
    "    # eliminar palabras con más de 2 vocales seguidas \"largooooo -> largoo\"\n",
    "    res_txt = re.sub(\"([A-Za-z])\\\\1{2,}\", \"\\\\1\\\\1\", res_txt)\n",
    "    \n",
    "    # eliminar espacios y tabulaciones repetidas\n",
    "    res_txt = re.sub(\"[ \\t]+\", \" \", res_txt.strip())\n",
    "    \n",
    "    # mantener solamente caracteres alfanuméricos\n",
    "    res_txt = re.sub(r'[^a-zñÑA-Z0-9áéíóúÁÉÍÓÚ ]', '', res_txt)\n",
    "    return res_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En *prepare_tweet* eliminamos las *stopwords*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tweet(text):\n",
    "    stop_words = nltk.corpus.stopwords.words('spanish')\n",
    "    custom_stop_words = [\"d\", \"q\"]\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    tokens = [w for w in tokens if w not in custom_stop_words]\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    \n",
    "    # stemming\n",
    "    #tokens = [stemmer.stem(w) for w in tokens]\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el preprocesado, obteniendo el siguiente resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original :\n",
      " ;-)) RT @doloresvela: El #iPhone 5 podría ser presentado en marzo http://t.co/2kjKTjfF\n",
      "Resultado :\n",
      " rt el iphone 5 podría ser presentado marzo\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original :\\n {df_tweets['content'][8235]}\")\n",
    "\n",
    "content = df_tweets['content']\n",
    "\n",
    "content = content.apply(lambda tweet: prepare_tweet(clean_tweet(str(tweet))))\n",
    "\n",
    "df_tweets['content'] = content\n",
    "\n",
    "print(f\"Resultado :\\n {df_tweets['content'][8235]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear dataset de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado se crea el dataset de entrenamiento.\n",
    "\n",
    "Unimos los dataframes en uno solo, que contiene el id del tweet, el contenido del tweet y la categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23782 entries, 0 to 23781\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   tweetid  23782 non-null  int64 \n",
      " 1   content  23782 non-null  object\n",
      " 2   value    23782 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 557.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data_tweets = df_tweets[['tweetid', 'content']]\n",
    "data_sentim = df_polarities[['tweetid', 'value']]\n",
    "\n",
    "data_tweets = data_tweets.merge(data_sentim, on=\"tweetid\").drop_duplicates(subset='tweetid', keep=\"first\").reset_index(drop=True)\n",
    "data_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se cambia la etiqueta por un valor numérico que indica la clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Número de tweets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Número de tweets\n",
       "value                  \n",
       "0                  6219\n",
       "1                   976\n",
       "2                  5597\n",
       "3                  2755\n",
       "4                  5442\n",
       "5                  2793"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id = {\"N\": 0,\n",
    "            \"N+\": 1,\n",
    "            \"NONE\": 2,\n",
    "            \"NEU\": 3,\n",
    "            \"P\": 4,\n",
    "            \"P+\": 5}\n",
    "\n",
    "NUMBER_CLASSES = 6\n",
    "\n",
    "data_tweets[\"value\"].replace(label2id, inplace=True)\n",
    "\n",
    "data_tweets[['value', 'tweetid']].drop_duplicates(subset='tweetid', keep=\"first\").groupby(\"value\").count().rename(columns={\"value\": \"Categoría\", \"tweetid\": \"Número de tweets\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la variable *apply_balance* controlamos si queremos aplicar o no balanceo de datos.\n",
    "\n",
    "En el caso de utilizar 6 clases, no aplicamos balanceo de datos, pues perderíamos la mayoría de los tweets debido a que la clase N+ tiene muchos menos tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_balance = False\n",
    "\n",
    "if apply_balance:\n",
    "    g = data_tweets.groupby('value')\n",
    "    data_tweets = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))\n",
    "    data_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizar contenido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se tokeniza el texto, convirtiendo las palabras a números enteros, y añadiendo un token de clasificación *[CLS]* al inicio de la frase. Para esto se utiliza la clase *BertTokenizer* con los pesos de *BETO*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = 'dccuchile/bert-base-spanish-wwm-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos el tweet de mayor longitud y asignamos un valor de longitud mayor, para que la longitud de las frases tokenizadas contenga todos los tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = data_tweets['content']\n",
    "tok = tweets.apply(lambda tuit: tokenizer.encode(tuit, add_special_tokens=True))\n",
    "tok.apply(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_token_len = 55\n",
    "\n",
    "def tokenizar(df):\n",
    "    # tokeniza texto y genera máscara de atención\n",
    "    tweets = df['content'].tolist()\n",
    "    tokenize_result = tokenizer(tweets,\n",
    "                                add_special_tokens=True, \n",
    "                                max_length=max_token_len,\n",
    "                                return_attention_mask=True,\n",
    "                                padding='max_length')\n",
    "    \n",
    "    data_tensor = torch.LongTensor(tokenize_result.input_ids)\n",
    "    mask_tensor = torch.LongTensor(tokenize_result.attention_mask)\n",
    "    \n",
    "    # crea etiquetas\n",
    "    polarity_id = df['value'].tolist()\n",
    "    \n",
    "    target_tensor = torch.tensor(polarity_id)\n",
    "    \n",
    "    return data_tensor, target_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de tokenizar el texto, se crea un vector adicional llamado *attention mask*. Esta máscara indica al *transformer* donde está realmente el contenido de la frase, para así evitar aplicar mecanismos de atención sobre los tokens de *padding*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    4,  1035, 10406, 30956,  1836,  1948,  2803,  2403,  1361, 20922,\n",
       "          1200,  1544, 20578, 30958,  1002, 28253,  1250,  7684,     5,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1]),\n",
       " tensor(4),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, target, mask = tokenizar(data_tweets)\n",
    "\n",
    "data[0], target[0], mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    4,  1733,  1784, 30962, 11441,  2566, 30957,  2030, 15491,  2849,\n",
       "          1825, 17810, 30958, 11925,  1943, 14352,  1137,  5489,  4878, 30955,\n",
       "             5,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1]),\n",
       " ['[CLS]',\n",
       "  'nom',\n",
       "  '##eo',\n",
       "  '##l',\n",
       "  '##vido',\n",
       "  'aprob',\n",
       "  '##o',\n",
       "  'ley',\n",
       "  'aborto',\n",
       "  'libre',\n",
       "  'todas',\n",
       "  'ministra',\n",
       "  '##s',\n",
       "  'salta',\n",
       "  '##ban',\n",
       "  'alegr',\n",
       "  '##ia',\n",
       "  'congreso',\n",
       "  'llor',\n",
       "  '##e',\n",
       "  '[SEP]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2], tokenizer.convert_ids_to_tokens(data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sets de entrenamiento, validación y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos el *dataset* en entrenamiento, validación y test. Con la opción *stratify* aseguramos que se mantenga la misma proporción de clases para cada conjunto que el *dataset* original. Para asegurarlo, es posible que se pierdan ciertos tweets. Esta operación no balancea el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.90\n",
    "val_size = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([21403, 55]), torch.Size([1189, 55]), torch.Size([1190, 55]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_val, target_train, target_val, mask_train, mask_val = train_test_split(data, target, mask, test_size=1-train_size, stratify=target)\n",
    "\n",
    "data_val, data_test, target_val, target_test, mask_val, mask_test = train_test_split(data_val, target_val, mask_val, test_size=1-(val_size/(1-train_size)), stratify=target_val)\n",
    "\n",
    "data_train.shape, data_val.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase *TweetDataset* permite iterar sobre el *dataset* devolviendo los *tokens*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, target, mask):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.mask = mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.target[idx], self.mask[idx]\n",
    "\n",
    "train_dataset = TweetDataset(data_train, target_train, mask_train)\n",
    "val_dataset   = TweetDataset(data_val, target_val, mask_val)\n",
    "test_dataset  = TweetDataset(data_test, target_test, mask_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de clasificación *Bert*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente modelo utiliza la clase *BertModel* del módulo *transformers* de [*HuggingFace*](https://huggingface.co/transformers/) para clasificar los textos. La salida del *transformer* para el token *[CLS]* se combina con dos capas *fully connected*, generando un vector *one-hot* que indica la clase.\n",
    "\n",
    "El modelo tiene tres métodos para serializar: *load_from*, *save_to* y *checkpoint*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierTransformerModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, transformer_dim, hidden_dim, n_out, initialize_transformer=True):\n",
    "        super(ClassifierTransformerModel, self).__init__()\n",
    "        \n",
    "        self.transformer_model = None\n",
    "        if initialize_transformer:\n",
    "            self.transformer_model = BertModel.from_pretrained(BASE_MODEL)\n",
    "        \n",
    "        self.in_classifier = nn.Linear(transformer_dim, hidden_dim)\n",
    "        self.out_classifier = nn.Linear(hidden_dim, n_out)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        \n",
    "        transformer_out = self.transformer_model(x, attention_mask=mask).last_hidden_state\n",
    "        cls_out = transformer_out[:, 0, :]\n",
    "        \n",
    "        hidden_t = self.in_classifier(cls_out)\n",
    "        hidden_t = self.out_classifier(hidden_t)\n",
    "        \n",
    "        return F.log_softmax(hidden_t, dim=-1)\n",
    "    \n",
    "    def save_to(self, folder):\n",
    "        \"\"\"\n",
    "        folder/model_*datestamp*/transformer/...\n",
    "        folder/model_*datestamp*/classifier/...\n",
    "        \"\"\"\n",
    "        \n",
    "        # save model\n",
    "        self.transformer_model.save_pretrained(folder / Path(\"transformer\"))\n",
    "        \n",
    "        (folder / Path(\"classifier\")).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        torch.save(self.state_dict(), folder / Path(\"classifier/model.pth\"))\n",
    "    \n",
    "    @classmethod\n",
    "    def load_from(cls, folder, dev, transformer_dim, hidden_dim, n_out):\n",
    "        \"\"\"\n",
    "        folder = folder/*datestamp*\n",
    "        \"\"\"\n",
    "        model = cls(transformer_dim, hidden_dim, n_out, initialize_transformer=False)\n",
    "        \n",
    "        recover_dict = torch.load(folder / Path(\"classifier/model.pth\"), map_location=dev) # all keys\n",
    "        model_dict = model.state_dict() # classifier keys\n",
    "        \n",
    "        filtered_dict = {k: v for k, v in recover_dict.items() if k in model_dict.keys()}\n",
    "        \n",
    "        model_dict.update(filtered_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "        \n",
    "        model.transformer_model = BertModel.from_pretrained(folder / Path(\"transformer\"))\n",
    "        return model.to(dev)\n",
    "    \n",
    "    def checkpoint(self, folder, optimizer, stats):\n",
    "        status = {\n",
    "            'state_dict': self.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        status = {**status, **stats}\n",
    "        \n",
    "        ts = datetime.datetime.now()\n",
    "        ts_str = f\"checkpoint_{ts.day}{ts.month}{ts.year}{ts.hour}{ts.minute}{ts.second}\"\n",
    "        (folder / Path(ts_str)).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        torch.save(status, folder / Path(ts_str) / Path(\"checkpoint.pth\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tamaño de salida del *BertModel* —768— será el tamaño de entrada de la primera *FFN*. Este valor se indica con la variable *n_subwords*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(BASE_MODEL, output_hidden_states=False).to(device)\n",
    "cuda_data = data_train[0:1].to(device)\n",
    "cuda_mask = mask_train[0:1].to(device)\n",
    "\n",
    "a = model(cuda_data, attention_mask=cuda_mask).last_hidden_state.shape\n",
    "del model\n",
    "del cuda_data\n",
    "del cuda_mask\n",
    "\n",
    "print(a[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las dos siguientes funciones definen el entrenamiento y validación de la red. Mediante el flag *stop_train* interrumpiendo el *kernel* con el botón de *stop* puede parase el entrenamiento en cualquier momento.\n",
    "\n",
    "Para evitar sobrecargar la memoria de la GPU, las variables de cargan a CUDA por *batches* únicamente en el momento de utilizarlas.\n",
    "\n",
    "El modelo final se almacena en el directorio elegido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subwords = 768\n",
    "n_hidden = 16\n",
    "n_categories = NUMBER_CLASSES\n",
    "\n",
    "model = ClassifierTransformerModel(n_subwords, n_hidden, n_categories).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 1e-6\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "patience = 20\n",
    "global stop_train\n",
    "stop_train = False\n",
    "\n",
    "def evaluation_iteration(model, loader, loss_function):\n",
    "    global stop_train\n",
    "    \n",
    "    total_acc = 0\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_step, (data, target, mask) in enumerate(loader):\n",
    "        try:\n",
    "            cuda_data = data.to(device)\n",
    "            cuda_target = target.to(device)\n",
    "            cuda_mask = mask.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(cuda_data, cuda_mask)\n",
    "\n",
    "                loss = loss_function(output, cuda_target)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                prediction = output.argmax(dim=1)\n",
    "\n",
    "                acc = accuracy_score(prediction.cpu(), cuda_target.cpu())#(prediction == cuda_target).cpu().numpy().mean()\n",
    "                prec = precision_score(prediction.cpu(), cuda_target.cpu(), average=\"macro\", zero_division=0.0)\n",
    "                rec = recall_score(prediction.cpu(), cuda_target.cpu(), average=\"macro\", zero_division=0.0)\n",
    "\n",
    "                total_acc += acc\n",
    "                total_precision += prec\n",
    "                total_recall += rec\n",
    "        except KeyboardInterrupt:\n",
    "            try: del cuda_data\n",
    "            except: pass\n",
    "\n",
    "            try: del cuda_target\n",
    "            except: pass\n",
    "\n",
    "            try: del cuda_mask\n",
    "            except: pass\n",
    "            \n",
    "            stop_train = True\n",
    "            print(\"*** train-data variables removed from cuda memory ***\")\n",
    "            break\n",
    "        \n",
    "        # Free variables\n",
    "        del cuda_data\n",
    "        del cuda_target\n",
    "        del cuda_mask\n",
    "    \n",
    "    T = len(loader)\n",
    "    return map(lambda r: r/T, [total_loss, total_acc, total_precision, total_recall])\n",
    "\n",
    "def train_iteration(folder, model, loader, loss_function, optim, nepochs, patience):\n",
    "    global stop_train\n",
    "    \n",
    "    loader_train = loader[0]\n",
    "    loader_val = loader[1]\n",
    "    \n",
    "    ts = datetime.datetime.now()\n",
    "    best_model_path = Path(f\"./temp/beto/best_model_{ts.day}{ts.month}{ts.year}{ts.hour}{ts.minute}{ts.second}\")\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True, path=best_model_path)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(1, nepochs+1):\n",
    "        \n",
    "        \n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        \n",
    "        progress_bar = tqdm.tqdm(train_loader, desc='Bar desc', leave=True)\n",
    "\n",
    "        for batch_step, (data, target, mask) in enumerate(progress_bar, 1):\n",
    "            \n",
    "            try:\n",
    "                cuda_data = data.to(device)\n",
    "                cuda_target = target.to(device)\n",
    "                cuda_mask = mask.to(device)\n",
    "\n",
    "                optim.zero_grad()\n",
    "\n",
    "                output = model(cuda_data, cuda_mask)\n",
    "\n",
    "                loss = loss_function(output, cuda_target)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                acc = accuracy_score(output.detach().cpu().argmax(dim=1), target)\n",
    "                total_acc += acc\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "                optim.step()\n",
    "                \n",
    "                progress_bar.set_description(f\"{epoch = } {batch_step = } loss = {total_loss / batch_step :0.4f} acc = {total_acc / batch_step :0.4f}\")\n",
    "            \n",
    "            except KeyboardInterrupt:\n",
    "                try: del cuda_data\n",
    "                except: pass\n",
    "                \n",
    "                try: del cuda_target\n",
    "                except: pass\n",
    "                \n",
    "                try: del cuda_mask\n",
    "                except: pass\n",
    "                print(\"*** train-data variables removed from cuda memory ***\")\n",
    "                global stop_train\n",
    "                stop_train = True\n",
    "                break\n",
    "            \n",
    "            # Free variables\n",
    "            del cuda_data\n",
    "            del cuda_target\n",
    "            del cuda_mask\n",
    "        \n",
    "        if stop_train: # stop from train\n",
    "            print(\"*** stoping training ***\")\n",
    "            break\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss, val_acc, val_prec, val_recall = evaluation_iteration(model, loader_val, loss_function)\n",
    "        model.train()\n",
    "        \n",
    "        if stop_train: # stop from evaluation\n",
    "            break\n",
    "        \n",
    "        print(\"*\"*20)\n",
    "        print(f\"{epoch = }/{nepochs} loss = {total_loss / len(loader_train) :.4f} acc = {total_acc / len(loader_train) :.4f} | {val_loss = :.4f} | {val_acc = :.4f} {val_prec = :.4f} {val_recall = :.4f}\")\n",
    "        print(\"*\"*20)\n",
    "        \n",
    "        stats = {\n",
    "            'epoch': epoch,\n",
    "            'total_epochs': nepochs,\n",
    "            'loss': total_loss / len(loader_train),\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_acc,\n",
    "            'val_precision': val_prec,\n",
    "            'val_recall': val_recall\n",
    "        }\n",
    "        \n",
    "        model.checkpoint(folder=folder,\n",
    "                         optimizer=optimizer,\n",
    "                         stats=stats)\n",
    "        \n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    \n",
    "    if not best_model_path.is_dir(): # there is no best model to save\n",
    "        return model\n",
    "    \n",
    "    # load best model found\n",
    "    best_model = ClassifierTransformerModel.load_from(folder=best_model_path,\n",
    "                                                      dev=device,\n",
    "                                                      transformer_dim=n_subwords,\n",
    "                                                      hidden_dim=n_hidden,\n",
    "                                                      n_out=n_categories)\n",
    "    \n",
    "    # save model\n",
    "    ts = datetime.datetime.now()\n",
    "    ts_str = f\"model_{ts.day}{ts.month}{ts.year}{ts.hour}{ts.minute}{ts.second}\"\n",
    "    best_model.save_to(folder / Path(ts_str))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 1 batch_step = 1338 loss = 1.5685 acc = 0.3704: 100%|████| 1338/1338 [09:18<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 1/100 loss = 1.5685 acc = 0.3704 | val_loss = 1.4224 | val_acc = 0.4405 val_prec = 0.3544 val_recall = 0.2688\n",
      "********************\n",
      "Validation loss decreased (inf --> 1.422391).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 2 batch_step = 1338 loss = 1.3709 acc = 0.4659: 100%|████| 1338/1338 [09:20<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 2/100 loss = 1.3709 acc = 0.4659 | val_loss = 1.3329 | val_acc = 0.4630 val_prec = 0.3697 val_recall = 0.3058\n",
      "********************\n",
      "Validation loss decreased (1.422391 --> 1.332904).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 3 batch_step = 1338 loss = 1.2965 acc = 0.4928: 100%|████| 1338/1338 [09:20<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 3/100 loss = 1.2965 acc = 0.4928 | val_loss = 1.2983 | val_acc = 0.4870 val_prec = 0.3964 val_recall = 0.3535\n",
      "********************\n",
      "Validation loss decreased (1.332904 --> 1.298311).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 4 batch_step = 1338 loss = 1.2566 acc = 0.5073: 100%|████| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 4/100 loss = 1.2566 acc = 0.5073 | val_loss = 1.2759 | val_acc = 0.4915 val_prec = 0.3995 val_recall = 0.3508\n",
      "********************\n",
      "Validation loss decreased (1.298311 --> 1.275895).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 5 batch_step = 1338 loss = 1.2249 acc = 0.5229: 100%|████| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 5/100 loss = 1.2249 acc = 0.5229 | val_loss = 1.2737 | val_acc = 0.4903 val_prec = 0.4196 val_recall = 0.4110\n",
      "********************\n",
      "Validation loss decreased (1.275895 --> 1.273665).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 6 batch_step = 1338 loss = 1.1922 acc = 0.5339: 100%|████| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 6/100 loss = 1.1922 acc = 0.5339 | val_loss = 1.2786 | val_acc = 0.4938 val_prec = 0.4160 val_recall = 0.4013\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 7 batch_step = 1338 loss = 1.1629 acc = 0.5493: 100%|████| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 7/100 loss = 1.1629 acc = 0.5493 | val_loss = 1.2689 | val_acc = 0.5030 val_prec = 0.4268 val_recall = 0.4101\n",
      "********************\n",
      "Validation loss decreased (1.273665 --> 1.268867).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 8 batch_step = 1338 loss = 1.1340 acc = 0.5595: 100%|████| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 8/100 loss = 1.1340 acc = 0.5595 | val_loss = 1.2772 | val_acc = 0.4928 val_prec = 0.4225 val_recall = 0.4108\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 9 batch_step = 1338 loss = 1.1079 acc = 0.5701: 100%|████| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 9/100 loss = 1.1079 acc = 0.5701 | val_loss = 1.2937 | val_acc = 0.4937 val_prec = 0.4258 val_recall = 0.4126\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 10 batch_step = 1338 loss = 1.0828 acc = 0.5850: 100%|███| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 10/100 loss = 1.0828 acc = 0.5850 | val_loss = 1.2828 | val_acc = 0.4930 val_prec = 0.4267 val_recall = 0.4167\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 11 batch_step = 1338 loss = 1.0557 acc = 0.5934: 100%|███| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 11/100 loss = 1.0557 acc = 0.5934 | val_loss = 1.3137 | val_acc = 0.4912 val_prec = 0.4285 val_recall = 0.4106\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 12 batch_step = 1338 loss = 1.0307 acc = 0.6015: 100%|███| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 12/100 loss = 1.0307 acc = 0.6015 | val_loss = 1.3166 | val_acc = 0.4825 val_prec = 0.4164 val_recall = 0.4229\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 13 batch_step = 1338 loss = 1.0041 acc = 0.6154: 100%|███| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 13/100 loss = 1.0041 acc = 0.6154 | val_loss = 1.3081 | val_acc = 0.5057 val_prec = 0.4401 val_recall = 0.4321\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 6 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 14 batch_step = 1338 loss = 0.9748 acc = 0.6259: 100%|███| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 14/100 loss = 0.9748 acc = 0.6259 | val_loss = 1.3466 | val_acc = 0.4875 val_prec = 0.4247 val_recall = 0.4297\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 7 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 15 batch_step = 1338 loss = 0.9550 acc = 0.6360: 100%|███| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 15/100 loss = 0.9550 acc = 0.6360 | val_loss = 1.3574 | val_acc = 0.4943 val_prec = 0.4397 val_recall = 0.4191\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 8 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 16 batch_step = 1338 loss = 0.9229 acc = 0.6494: 100%|███| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 16/100 loss = 0.9229 acc = 0.6494 | val_loss = 1.3659 | val_acc = 0.4950 val_prec = 0.4257 val_recall = 0.4397\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 9 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 17 batch_step = 1338 loss = 0.8959 acc = 0.6627: 100%|███| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 17/100 loss = 0.8959 acc = 0.6627 | val_loss = 1.3982 | val_acc = 0.4923 val_prec = 0.4325 val_recall = 0.4255\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 10 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 18 batch_step = 1338 loss = 0.8641 acc = 0.6727: 100%|███| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 18/100 loss = 0.8641 acc = 0.6727 | val_loss = 1.4041 | val_acc = 0.5013 val_prec = 0.4386 val_recall = 0.4390\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 11 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 19 batch_step = 1338 loss = 0.8388 acc = 0.6850: 100%|███| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 19/100 loss = 0.8388 acc = 0.6850 | val_loss = 1.4257 | val_acc = 0.4973 val_prec = 0.4555 val_recall = 0.4179\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 12 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 20 batch_step = 1338 loss = 0.8126 acc = 0.6949: 100%|███| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 20/100 loss = 0.8126 acc = 0.6949 | val_loss = 1.4606 | val_acc = 0.4912 val_prec = 0.4320 val_recall = 0.4286\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 13 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 21 batch_step = 1338 loss = 0.7866 acc = 0.7058: 100%|███| 1338/1338 [09:20<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 21/100 loss = 0.7866 acc = 0.7058 | val_loss = 1.4774 | val_acc = 0.4962 val_prec = 0.4330 val_recall = 0.4357\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 14 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 22 batch_step = 1338 loss = 0.7606 acc = 0.7192: 100%|███| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 22/100 loss = 0.7606 acc = 0.7192 | val_loss = 1.5022 | val_acc = 0.4895 val_prec = 0.4403 val_recall = 0.4274\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 15 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 23 batch_step = 1338 loss = 0.7302 acc = 0.7311: 100%|███| 1338/1338 [09:19<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 23/100 loss = 0.7302 acc = 0.7311 | val_loss = 1.5302 | val_acc = 0.4810 val_prec = 0.4180 val_recall = 0.4425\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 16 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 24 batch_step = 1338 loss = 0.7051 acc = 0.7399: 100%|███| 1338/1338 [09:18<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 24/100 loss = 0.7051 acc = 0.7399 | val_loss = 1.5699 | val_acc = 0.4895 val_prec = 0.4172 val_recall = 0.4172\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 17 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 25 batch_step = 1338 loss = 0.6754 acc = 0.7508: 100%|███| 1338/1338 [09:18<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 25/100 loss = 0.6754 acc = 0.7508 | val_loss = 1.5809 | val_acc = 0.4920 val_prec = 0.4355 val_recall = 0.4268\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 18 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 26 batch_step = 1338 loss = 0.6569 acc = 0.7598: 100%|███| 1338/1338 [09:18<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 26/100 loss = 0.6569 acc = 0.7598 | val_loss = 1.6286 | val_acc = 0.4728 val_prec = 0.4113 val_recall = 0.4163\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Bar desc:   0%|                                                             | 0/1338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 19 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 27 batch_step = 1338 loss = 0.6300 acc = 0.7717: 100%|███| 1338/1338 [09:18<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch = 27/100 loss = 0.6300 acc = 0.7717 | val_loss = 1.6419 | val_acc = 0.4798 val_prec = 0.4261 val_recall = 0.4242\n",
      "********************\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "directory = Path(f\"modelos_beto/train_{datetime.datetime.timestamp(datetime.datetime.now()):0.0f}\")\n",
    "best_model = train_iteration(directory, model, (train_loader, val_loader), criterion, optimizer, EPOCHS, patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos los parámetros utilizados junto al modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(directory / Path(\"parameters.txt\"), \"w\")\n",
    "f.write(f\"{n_hidden = }\\n\" + \\\n",
    "        f\"{lr = }\\n\" + \\\n",
    "        f\"{NUMBER_CLASSES = }\\n\"\n",
    "       )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val_loss = 1.2750 val_acc = 0.5012 val_prec = 0.4311 val_recall = 0.4064'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss, val_acc, val_prec, val_recall = evaluation_iteration(best_model, val_loader, criterion)\n",
    "\n",
    "f\"{val_loss = :.4f} {val_acc = :.4f} {val_prec = :.4f} {val_recall = :.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_loss = 1.2643 test_acc = 0.4908 test_prec = 0.4076 test_recall = 0.3849'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc, test_prec, test_recall = evaluation_iteration(best_model, test_loader, criterion)\n",
    "\n",
    "f\"{test_loss = :.4f} {test_acc = :.4f} {test_prec = :.4f} {test_recall = :.4f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 4px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con 3 clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha entrenado el *dataset* agrupado y **balanceado en 3 categorías** (positivo con P y P+, neutro con NEU y NONE, y negativo con N y N+).\n",
    "Los siguientes resultados se han obtenido recorriendo el *dataset* en ***batches* de tamaño 16**, y con **una *patience* a 5 del *early stopping***. \n",
    "\n",
    "El tamaño de *batches* es el máximo que permite la memoria de la GPU donde se entrenó la red. Se ha elegido un valor bajo de *patience* para reducir el tiempo de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th>lr</th>\n",
    "    <th>Hidden dim</th>\n",
    "    <th>8</th>\n",
    "    <th>16</th>\n",
    "    <th>32</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\"><b>1e-4</b></td>\n",
    "    <td><b>Loss</b></td>\n",
    "    <td>0.9899</td>\n",
    "    <td>0.9260</td>\n",
    "    <td>0.9397</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Accuracy</b></td>\n",
    "    <td>0.5267</td>\n",
    "    <td>0.5805</td>\n",
    "    <td>0.5610</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\"><b>1e-6</b></td>\n",
    "    <td><b>Loss</b></td>\n",
    "    <td>0.7660</td>\n",
    "    <td>0.7022</td>\n",
    "    <td>0.7532</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Accuracy</b></td>\n",
    "    <td>0.6622</td>\n",
    "    <td>0.6976</td>\n",
    "    <td>0.6730</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th>lr</th>\n",
    "    <th>Hidden dim</th>\n",
    "    <th>8</th>\n",
    "    <th>16</th>\n",
    "    <th>32</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td rowspan=\"4\"><b>1e-4</b></td>\n",
    "    <td><b>Loss</b></td>\n",
    "    <td>1.0009</td>\n",
    "    <td>0.8769</td>\n",
    "    <td>0.9882</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Accuracy</b></td>\n",
    "    <td>0.5192</td>\n",
    "    <td>0.6138</td>\n",
    "    <td>0.5247</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Precision</b></td>\n",
    "    <td>0.5139</td>\n",
    "    <td>0.6256</td>\n",
    "    <td>0.5201</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Recall</b></td>\n",
    "    <td>0.4010</td>\n",
    "    <td>0.6396</td>\n",
    "    <td>0.5253</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"4\"><b>1e-6</b></td>\n",
    "    <td><b>Loss</b></td>\n",
    "    <td>0.7975</td>\n",
    "    <td>0.7894</td>\n",
    "    <td>0.7989</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Accuracy</b></td>\n",
    "    <td>0.6578</td>\n",
    "    <td>0.6636</td>\n",
    "    <td>0.6580</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Precision</b></td>\n",
    "    <td>0.6513</td>\n",
    "    <td>0.6584</td>\n",
    "    <td>0.6581</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Recall</b></td>\n",
    "    <td>0.6459</td>\n",
    "    <td>0.6593</td>\n",
    "    <td>0.6703</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th>lr</th>\n",
    "    <th>Hidden dim</th>\n",
    "    <th>8</th>\n",
    "    <th>16</th>\n",
    "    <th>32</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td rowspan=\"4\"><b>1e-4</b></td>\n",
    "    <td><b>Loss</b></td>\n",
    "    <td>1.0063</td>\n",
    "    <td>0.8866</td>\n",
    "    <td>1.0004</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Accuracy</b></td>\n",
    "    <td>0.5138</td>\n",
    "    <td>0.6048</td>\n",
    "    <td>0.5184</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Precision</b></td>\n",
    "    <td>0.5095</td>\n",
    "    <td>0.6017</td>\n",
    "    <td>0.5149</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Recall</b></td>\n",
    "    <td>0.3857</td>\n",
    "    <td>0.6195</td>\n",
    "    <td>0.5328</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"4\"><b>1e-6</b></td>\n",
    "    <td><b>Loss</b></td>\n",
    "    <td>0.7981</td>\n",
    "    <td>0.8066</td>\n",
    "    <td>0.7945</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Accuracy</b></td>\n",
    "    <td>0.6461</td>\n",
    "    <td>0.6397</td>\n",
    "    <td>0.6581</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Precision</b></td>\n",
    "    <td>0.6344</td>\n",
    "    <td>0.6324</td>\n",
    "    <td>0.6551</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Recall</b></td>\n",
    "    <td>0.6402</td>\n",
    "    <td>0.6402</td>\n",
    "    <td>0.6525</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con 6 clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha entrenado el *dataset* agrupado y **con las 6 categorías**.\n",
    "Los siguientes resultados se han obtenido recorriendo el *dataset* en ***batches* de tamaño 16**, y con **una *patience* a 5 del *early stopping***. \n",
    "\n",
    "El tamaño de *batches* es el máximo que permite la memoria de la GPU donde se entrenó la red. Se ha elegido un valor bajo de *patience* para reducir el tiempo de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th>lr</th>\n",
    "    <th>Hidden dim</th>\n",
    "    <th>8</th>\n",
    "    <th>16</th>\n",
    "    <th>32</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\"><b>1e-4</b></td>\n",
    "    <td><b>Loss</b></td>\n",
    "    <td>1.4271</td>\n",
    "    <td>1.2971</td>\n",
    "    <td>1.4243</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Accuracy</b></td>\n",
    "    <td>0.4435</td>\n",
    "    <td>0.5159</td>\n",
    "    <td>0.4463</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\"><b>1e-6</b></td>\n",
    "    <td><b>Loss</b></td>\n",
    "    <td>1.2457</td>\n",
    "    <td>1.1629</td>\n",
    "    <td>1.1655</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Accuracy</b></td>\n",
    "    <td>0.5157</td>\n",
    "    <td>0.5493</td>\n",
    "    <td>0.5481</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th>lr</th>\n",
    "    <th>Hidden dim</th>\n",
    "    <th>8</th>\n",
    "    <th>16</th>\n",
    "    <th>32</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td rowspan=\"4\"><b>1e-4</b></td>\n",
    "    <td><b>Loss</b></td>\n",
    "    <td>1.3767</td>\n",
    "    <td>1.4305</td>\n",
    "    <td>1.3279</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Accuracy</b></td>\n",
    "    <td>0.4443</td>\n",
    "    <td>0.4612</td>\n",
    "    <td>0.4738</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Precision</b></td>\n",
    "    <td>0.3664</td>\n",
    "    <td>0.3639</td>\n",
    "    <td>0.3746</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Recall</b></td>\n",
    "    <td>0.3283</td>\n",
    "    <td>0.2809</td>\n",
    "    <td>0.3096</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"4\"><b>1e-6</b></td>\n",
    "    <td><b>Loss</td>\n",
    "    <td>1.2832</td>\n",
    "    <td>1.2689</td>\n",
    "    <td>1.2797</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Accuracy</b></td>\n",
    "    <td>0.4997</td>\n",
    "    <td>0.5030</td>\n",
    "    <td>0.4895</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Precision</b></td>\n",
    "    <td>0.4270</td>\n",
    "    <td>0.4268</td>\n",
    "    <td>0.4104</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Recall</b></td>\n",
    "    <td>0.3831</td>\n",
    "    <td>0.4101</td>\n",
    "    <td>0.3970</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th>lr</th>\n",
    "    <th>Hidden dim</th>\n",
    "    <th>8</th>\n",
    "    <th>16</th>\n",
    "    <th>32</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td rowspan=\"4\"><b>1e-4</b></td>\n",
    "    <td><b>Loss</b></td>\n",
    "    <td>1.3336</td>\n",
    "    <td>1.4271</td>\n",
    "    <td>1.3293</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Accuracy</b></td>\n",
    "    <td>0.4900</td>\n",
    "    <td>0.4733</td>\n",
    "    <td>0.4828</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Precision</b></td>\n",
    "    <td>0.4108</td>\n",
    "    <td>0.3779</td>\n",
    "    <td>0.3926</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Recall</b></td>\n",
    "    <td>0.3606</td>\n",
    "    <td>0.2784</td>\n",
    "    <td>0.3268</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"4\"><b>1e-6</b></td>\n",
    "    <td><b>Loss</b></td>\n",
    "    <td>1.2907</td>\n",
    "    <td>1.2643</td>\n",
    "    <td>1.2641</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Accuracy</b></td>\n",
    "    <td>0.4975</td>\n",
    "    <td>0.4908</td>\n",
    "    <td>0.4933</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Precision</b></td>\n",
    "    <td>0.4079</td>\n",
    "    <td>0.4076</td>\n",
    "    <td>0.4185</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Recall</b></td>\n",
    "    <td>0.3728</td>\n",
    "    <td>0.3849</td>\n",
    "    <td>0.4004</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
